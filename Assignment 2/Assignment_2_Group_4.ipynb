{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2 - Group 4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CeesGniewyk/Recommender-Systems/blob/master/Assignment_2_Group_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkyt5og60lPd",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gI3dWlioVJtb"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PSB5vAQvVJts"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HJkoF3HRVJtf",
        "outputId": "63b04e3a-e7b1-4d03-833c-512e9eb4eea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Lambda, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.regularizers import l2\n",
        "from keras.losses import binary_crossentropy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8MqrDU6NVJtw",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn6RwvEez06M",
        "colab_type": "text"
      },
      "source": [
        "## Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MfUX0GxFT2q6",
        "outputId": "b929d4d6-bb35-4d98-ac1c-c4974f3f50ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WwXLJ5Devge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pTyhLjDwVJt_",
        "outputId": "b501d71f-f90b-4c3c-8e22-9b0706757db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rAuIik9iVJuO"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92defhzSVJuP",
        "outputId": "02c72717-16c7-478a-f375-b5e1205a4db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "classes = \"beaver dolphin otter seal whale aquarium-fish flatfish ray shark trout orchids poppies roses sunflowers tulips bottles bowls cans cups plates apples mushrooms oranges pears sweet-peppers clock computer-keyboard lamp telephone television bed chair couch table wardrobe bee beetle butterfly caterpillar cockroach bear leopard lion tiger, wolf bridge, castle, house, road, skyscraper cloud, forest, mountain, plain, sea camel, cattle, chimpanzee, elephant, kangaroo fox, porcupine, possum, raccoon, skunk crab, lobster, snail, spider, worm baby, boy, girl, man, woman crocodile, dinosaur, lizard, snake, turtle hamster, mouse, rabbit, shrew, squirrel maple, oak, palm, pine, willow bicycle, bus, motorcycle, pickup-truck, train lawn-mower, rocket, streetcar, tank, tractor\"\n",
        "class_labels = classes.replace(\",\",\"\").split()\n",
        "class_labels.sort()\n",
        "print(class_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['apples', 'aquarium-fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottles', 'bowls', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'cans', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'computer-keyboard', 'couch', 'crab', 'crocodile', 'cups', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'lamp', 'lawn-mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple', 'motorcycle', 'mountain', 'mouse', 'mushrooms', 'oak', 'oranges', 'orchids', 'otter', 'palm', 'pears', 'pickup-truck', 'pine', 'plain', 'plates', 'poppies', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'roses', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflowers', 'sweet-peppers', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulips', 'turtle', 'wardrobe', 'whale', 'willow', 'wolf', 'woman', 'worm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pFxApXYjVJuY",
        "outputId": "92f27c85-5230-47e3-e09c-e49a035183e1",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "example_id = 0 # pick any integer from 0 to 49999 to visualize a training example\n",
        "example = x_train[example_id]\n",
        "label = y_train[example_id]\n",
        "print(\"Class label:\", class_labels[label[0]])\n",
        "plt.imshow(example)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class label: cattle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKXJ+ISJFzi9EpPx/IX9Wz6GSKX8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GpW8hIynVJug"
      },
      "source": [
        "## Splitting the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XZh9QVFJVJui",
        "outputId": "bbc71f23-3f73-49a1-d3cd-634f2975a545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "selection = y_train < 80\n",
        "selection = selection.reshape(50000)\n",
        "invertselection = selection == False\n",
        "#Note the X,Y are capitalized for the split data\n",
        "Y_train = y_train[selection]\n",
        "X_train = x_train[selection]\n",
        "Y_oneshot_train = y_train[invertselection] \n",
        "X_oneshot_train = x_train[invertselection]\n",
        "print(Y_train.shape)\n",
        "print(X_train.shape)\n",
        "print(Y_oneshot_train.shape)\n",
        "print(X_oneshot_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 1)\n",
            "(40000, 32, 32, 3)\n",
            "(10000, 1)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q7qL-14JVJuq",
        "colab": {}
      },
      "source": [
        "training = np.zeros((80,500,32,32,3))\n",
        "for category in range(80):\n",
        "    example_nr = 0\n",
        "    for j in range(len(X_train)):\n",
        "        if (Y_train[j][0] == category):\n",
        "            training[category][example_nr]=X_train[j]\n",
        "            example_nr +=1            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wadOg5fAVJuv",
        "outputId": "aaa3ec47-354d-4e82-cf39-8bb79579fd22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "example_class = 12# pick any integer from 0 to 79\n",
        "example_nr = 2 # pick any integer from 0 to 499 to visualize a training example\n",
        "example = training[example_class][example_nr]\n",
        "print(\"Class label:\", class_labels[example_class])\n",
        "plt.imshow(example.astype(np.uint8))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class label: bridge\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IROq5fYjVJu1",
        "colab": {}
      },
      "source": [
        "One_shot_testing = np.zeros((20,500,32,32,3))\n",
        "for category in range(80,100):\n",
        "    example_nr = 0\n",
        "    realcategory = category-80\n",
        "    for j in range(len(X_oneshot_train)):\n",
        "        if (Y_oneshot_train[j][0] == category):\n",
        "            One_shot_testing[realcategory][example_nr]=X_oneshot_train[j]\n",
        "            example_nr +=1            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y9AL-a9FVJu5",
        "outputId": "0079eaf8-f785-48ff-ee0f-b99c9ee3acc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "example_class = 7 # pick any integer from 0 to 19\n",
        "example_nr = 50 # pick any integer from 0 to 499 to visualize a training example\n",
        "example = One_shot_testing[example_class][example_nr]\n",
        "print(\"Class label:\", class_labels[example_class+80])\n",
        "plt.imshow(example.astype(np.uint8))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class label: television\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uj4T8PEHGbMF"
      },
      "source": [
        "# Question 1: Siamese networks & one-shot learning (7pt)\n",
        "The Cifar-100 dataset is similar to the Cifar-10 dataset. It also consists of 60,000 32x32 RGB images, but they are distributed over 100 classes instead of 10. Thus, each class has much fewer examples, only 500 training images and 100 testing images per class. For more info about the dataset, see https://www.cs.toronto.edu/~kriz/cifar.html.\n",
        "\n",
        "*HINT: Import the Cifar-100 dataset directly from Keras, no need to download it from the website. Use* `label_mode=\"fine\"`\n",
        "\n",
        "### Task 1.1: Siamese network\n",
        "**a)**\n",
        "* Train a Siamese Network on the first 80 classes of (the training set of) Cifar-100, i.e. let the network predict the probability that two input images are from the same class. Use 1 as a target for pairs of images from the same class (positive pairs), and 0 for pairs of images from different classes (negative pairs). Randomly select image pairs from Cifar-100, but make sure you train on as many positive pairs as negative pairs.\n",
        "\n",
        "* Evaluate the performance of the network on 20-way one-shot learning tasks. Do this by generating 250 random tasks and obtain the average accuracy for each evaluation round. Use the remaining 20 classes that were not used for training. The model should perform better than random guessing.\n",
        "\n",
        "For this question you may ignore the test set of Cifar-100; it suffices to use only the training set and split this, using the first 80 classes for training and the remaining 20 classes for one-shot testing.\n",
        "\n",
        "*HINT: First sort the data by their labels (see e.g.* `numpy.argsort()`*), then reshape the data to a shape of* `(n_classes, n_examples, width, height, depth)`*, similar to the Omniglot data in Practical 4. It is then easier to split the data by class, and to sample positive and negative images pairs for training the Siamese network.*\n",
        "\n",
        "*NOTE: do not expect the one-shot accuracy for Cifar-100 to be similar to that accuracy for Omniglot; a lower accuracy can be expected. However, accuracy higher than random guess is certainly achievable.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q_ciVkD2C4u",
        "colab_type": "text"
      },
      "source": [
        "### Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IhWhCKctVJu9",
        "colab": {}
      },
      "source": [
        "def get_batch(batch_size, X):\n",
        "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
        "    n_classes, n_examples, w, h, d = X.shape\n",
        "    # randomly sample several classes to use in the batch\n",
        "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
        "    # initialize 2 empty arrays for the input image batch\n",
        "    pairs = [np.zeros((batch_size, h, w, d)) for i in range(2)]\n",
        "    # initialize vector for the targets, and make one half of it '1's, so 2nd half of batch has same class\n",
        "    targets = np.zeros((batch_size,))\n",
        "    targets[batch_size//2:] = 1\n",
        "    for i in range(batch_size):\n",
        "        category = categories[i]\n",
        "        idx_1 = np.random.randint(0, n_examples)\n",
        "        pairs[0][i, :, :, :] = X[category, idx_1].reshape(w, h,d)\n",
        "        idx_2 = np.random.randint(0, n_examples)\n",
        "        # pick images of same class for 1st half, different for 2nd\n",
        "        if i >= batch_size // 2:\n",
        "            category_2 = category\n",
        "        else:\n",
        "            #add a random number to the category modulo n_classes to ensure 2nd image has different category\n",
        "            category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
        "        pairs[1][i, :, :, :] = X[category_2,idx_2].reshape(w, h,d)\n",
        "    return pairs, targets\n",
        "\n",
        "def batch_generator(batch_size, X):\n",
        "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
        "    while True:\n",
        "        pairs, targets = get_batch(batch_size, X)\n",
        "        yield (pairs, targets)\n",
        "\n",
        "def train(model, X_train, batch_size=64, steps_per_epoch=100, epochs=1):\n",
        "    model.fit_generator(batch_generator(batch_size, training), steps_per_epoch=steps_per_epoch, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t-2fEVRFVJvB",
        "outputId": "e8175402-705b-4485-9a06-4f2d307ef8e7",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1112
        }
      },
      "source": [
        "input_shape = (32, 32, 3)\n",
        "left_input = Input(input_shape)\n",
        "right_input = Input(input_shape)\n",
        "\n",
        "# build convnet to use in each siamese 'leg'\n",
        "convnet = Sequential()\n",
        "convnet.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
        "# convnet.add(MaxPooling2D()) I think max pooling over an image where it doesn't fit causes errors\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(Dropout(0.25))\n",
        "convnet.add(Conv2D(128, (7,7), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "convnet.add(MaxPooling2D())\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(Dropout(0.25))\n",
        "convnet.add(Conv2D(128, (4,4), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "convnet.add(MaxPooling2D())\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(Dropout(0.25))\n",
        "convnet.add(Conv2D(256, (4,4), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "convnet.add(Flatten())\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(Dropout(0.25))\n",
        "convnet.add(Dense(4096, activation=\"sigmoid\", kernel_regularizer=l2(1e-3)))\n",
        "convnet.summary()\n",
        "\n",
        "# encode each of the two inputs into a vector with the convnet\n",
        "encoded_l = convnet(left_input)\n",
        "encoded_r = convnet(right_input)\n",
        "\n",
        "# merge two encoded inputs with the L1 distance between them, and connect to prediction output layer\n",
        "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
        "both = Lambda(L1_distance)([encoded_l, encoded_r])\n",
        "prediction = Dense(1, activation='sigmoid')(both)\n",
        "siamese_net = Model(inputs=[left_input,right_input], outputs=prediction)\n",
        "\n",
        "\n",
        "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "siamese_net.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 128)       200832    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 128)         262272    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 1, 1, 256)         524544    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              1052672   \n",
            "=================================================================\n",
            "Total params: 2,043,392\n",
            "Trainable params: 2,042,304\n",
            "Non-trainable params: 1,088\n",
            "_________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 4096)         2043392     input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,047,489\n",
            "Trainable params: 2,046,401\n",
            "Non-trainable params: 1,088\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G-QJwH_qVJvF",
        "colab": {}
      },
      "source": [
        "def make_oneshot_task(N, X):\n",
        "    \"\"\"Create pairs of (test image, support set image) with ground truth, for testing N-way one-shot learning.\"\"\"\n",
        "    n_classes, n_examples, w, h, d = X.shape\n",
        "    indices = np.random.randint(0, n_examples, size=(N,))\n",
        "    categories = np.random.choice(range(n_classes), size=(N,), replace=False)            \n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = np.random.choice(n_examples, replace=False, size=(2,))\n",
        "    test_image = np.asarray([X[true_category, ex1, :, :]]*N).reshape(N, w, h, d)\n",
        "    support_set = X[categories, indices, :, :]\n",
        "    support_set[0, :, :] = X[true_category, ex2]\n",
        "    support_set = support_set.reshape(N, w, h, d)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image, support_set]\n",
        "    return pairs, targets\n",
        "\n",
        "def test_oneshot(model, X, N=20, k=250, verbose=True):\n",
        "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net over k one-shot tasks.\"\"\"\n",
        "    n_correct = 0\n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {}-way one-shot learning tasks ...\".format(k, N))\n",
        "    for i in range(k):\n",
        "        inputs, targets = make_oneshot_task(N, X)\n",
        "        probs = model.predict(inputs)\n",
        "        if np.argmax(probs) == np.argmax(targets):\n",
        "            n_correct += 1\n",
        "    percent_correct = (100.0*n_correct / k)\n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\".format(percent_correct, N))\n",
        "    return percent_correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LfNBpqD18HU",
        "colab_type": "text"
      },
      "source": [
        "### Run cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iEFrsInYVJvH",
        "outputId": "5be99d19-c9a3-4eca-830b-fa98b977d5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "\n",
        "path = \"content/gdrive/My Drive/Project Support List/Colab Notebooks/models\"\n",
        "loops = 10\n",
        "best_acc = 0\n",
        "for i in range(loops):\n",
        "    print(\"=== Training loop {} ===\".format(i+1))\n",
        "    train(siamese_net, X_train)\n",
        "    test_acc = test_oneshot(siamese_net, One_shot_testing)\n",
        "    if test_acc >= best_acc:\n",
        "        print(\"New best one-shot accuracy, saving model ...\")\n",
        "        siamese_net.save('model.h5')\n",
        "        best_acc = test_acc\n",
        "model_file = drive.CreateFile({'title' : 'model.h5'})                       \n",
        "model_file.SetContentFile('model.h5')                       \n",
        "model_file.Upload()\n",
        "drive.CreateFile({'id': model_file.get('id')})    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Training loop 1 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.6863\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 8.8% accuracy for 20-way one-shot learning\n",
            "New best one-shot accuracy, saving model ...\n",
            "=== Training loop 2 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6864\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
            "New best one-shot accuracy, saving model ...\n",
            "=== Training loop 3 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6909\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 4 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.6847\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 9.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 5 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6893\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 6 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6799\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
            "New best one-shot accuracy, saving model ...\n",
            "=== Training loop 7 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6873\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 8 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6885\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 8.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 9 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6895\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 10 ===\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6915\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '14SdEFTp1LQuqeonHo8DFX08usE2c2zHQ'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "COiAqXWDAgCe"
      },
      "source": [
        "***\n",
        "\n",
        "**b)** Compare the performance of your Siamese network for Cifar-100 to the Siamese network from Practical 4 for Omniglot. Name three fundamental differences between the Cifar-100 and Omniglot datasets. How do these differences influence the difference in one-shot accuracy?\n",
        "\n",
        "**Answer:** <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IIHkoQ0PBWuB"
      },
      "source": [
        "The overall accuracy is 12.0%, which better than a random guess <br>\n",
        "\n",
        "<b>Differences regarding the images itself:</b>\n",
        "<br>The data is RGB instead of 1 dimensional, The images of the Cifar-100 data set are more noisy, the language dataset is very clean, The images in the CIFAR-100 dataset have a much lower resolution <br>\n",
        "<b> Differences regarding the classes and availability of data:</b> \n",
        "<br>The omniglot training dataset has metaclasses: 30 languages in the training set and 20 languages in the test set, each with an average of about 32 characters. Each character has 20 examples <br>\n",
        "the Cifar-100 dataset has 80 classes in the training set, 20 in the test set with 500 examples for each class.\n",
        "<br><br>\n",
        "<b> Overall influence of differences: </b> <br>\n",
        "In comparison the Cifar-100 dataset has more data images per class, but also has less detailed images. <br>\n",
        "These differences are making it more difficult for the model to find the differences between the images in the Cifar-100 data set compared to the Omniglot. The model will most likely run faster due to the lower resolutions, but will have a higher difficulty finding characteristics that distinguish the different models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VWpFF_5-Bf4B"
      },
      "source": [
        "***\n",
        "\n",
        "# Task 1.2: One-shot learning with neural codes\n",
        "**a)**\n",
        "* Train a CNN classifier on the first 80 classes of Cifar-100. Make sure it achieves at least 40% classification accuracy on those 80 classes (use the test set to validate this accuracy).\n",
        "* Then use neural codes from one of the later hidden layers of the CNN with L2-distance to evaluate one-shot learning accuracy for the remaining 20 classes of Cifar-100 with 250 random tasks. I.e. for a given one-shot task, obtain neural codes for the test image as well as the support set. Then pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qU7rNa157v6r",
        "colab": {}
      },
      "source": [
        "# === add code here ==="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M1BDzdPAz26B"
      },
      "source": [
        "***\n",
        "\n",
        "**b)** Briefly motivate your CNN architecture, and discuss the difference in one-shot accuracy between the Siamese network approach and the CNN neural codes approach.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oRpVm956FR8P"
      },
      "source": [
        "The architecture that would have been implemented would have been the architecture in Task 1.1 without the last layer of the siamese network. To get the neural codes the last dense layer is used. The difference in architecture would most likely be that the CNN neural codes approach uses more information to come to a decision. <br>\n",
        "The CNN is trained to classify the images to the appropriate class <br> the Siamese network is a neural network made to compare the neural codes of two images and train the network on the misclassification of the pairs of images (Either similar or dissimilar) <br>\n",
        "The Siamese network is only concerned about the differences between 2 images in every training step, whereas the CNN for the neural codes is doing a 80-way classification. <br> \n",
        "The models learn in different ways, therefore the One-shot task will have different outcomes. <br>\n",
        "Furthermore, for the siamese network the model is retrained after each batch of one-shot tasks. The CNN for the neural codes isn't retrained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-gkaM1tCThc"
      },
      "source": [
        "***\n",
        "# Question 2: Triplet networks & one-shot learning (10pt)\n",
        "\n",
        "### Task 2.1: Train a triplet network\n",
        "**a)**\n",
        "* Train a triplet network on the first 80 classes of (the training set of) Cifar-100.\n",
        " \n",
        "* Make sure the network achieves a smaller loss than the margin and the network does not collapse all representations to zero vectors. *HINT: If you experience problems to achieve this goal, it might be helpful to tinker the learning rate.*\n",
        "\n",
        "* You are provided with a working example of triplet loss implementation for Keras below. You may directly use it.\n",
        "\n",
        "You may ignore the test set of Cifar-100 for this question as well. It suffices to use only the training set and split this, using the first 80 classes for training and the remaining 20 classes for one-shot testing.\n",
        "\n",
        "```python\n",
        "# Notice that ground truth variable is not used for loss calculation. It is used as a function argument to by-pass some Keras functionality. This is because the network structure already implies the ground truth for the anchor image with the \"positive\" image.\n",
        "import tensorflow as tf\n",
        "def triplet_loss(ground_truth, network_output):\n",
        "\n",
        "    anchor, positive, negative = tf.split(network_output, num_or_size_splits=3, axis=1)        \n",
        "    \n",
        "    for embedding in [anchor, positive, negative]:\n",
        "        embedding = tf.math.l2_normalize(embedding)\n",
        "\n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=1)\n",
        "    \n",
        "    margin = # define your margin\n",
        "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), margin)\n",
        "    loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), axis=0)\n",
        "\n",
        "    return loss\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FIHD8l_rRLy5",
        "colab": {}
      },
      "source": [
        "# === add code here ==="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XHGJp45AR1qm"
      },
      "source": [
        "***\n",
        "\n",
        "### Task 2.2: One-shot learning with triplet neural codes\n",
        "**a)**\n",
        "* Use neural codes from the triplet network with L2-distance to evaluate one-shot learning accuracy for the remaining 20 classes of Cifar-100 with 250 random tasks. I.e. for a given one-shot task, obtain neural codes for the test image as well as the support set. Then pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction.\n",
        "* Explicitly state the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7w6o8xIXUADN",
        "colab": {}
      },
      "source": [
        "# === add code here ==="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CCcmbz0UU7mR"
      },
      "source": [
        "***\n",
        "## Question 3: Performance comparison (3pt)\n",
        "\n",
        "\n",
        "**a)** What accuracy would random guessing achieve (on average) on this dataset? Motivate your answer briefly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BKGDydqsVVX1"
      },
      "source": [
        "<b>Answer</b> <br>\n",
        "Random guessing on the *whole dataset* would be a 1% chance of getting it right. <br>\n",
        "We are however using the one-shot method where we use 20 of the classes, which gives the random guess a 5% accuracy <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5KLXRv-eV04Q"
      },
      "source": [
        "**b)** Discuss and compare the performances of networks in tasks 1.1, 1.2 and 2.2. Briefly motivate and explain which task would be expected the highest accuracy. Explain the reasons of the accuracy difference if there are any. If there is almost no difference accuracy, explain the reason for that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "71kTHFBkcjp8"
      },
      "source": [
        "The Triplet Neural codes are expected to score the highest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tB03J7d5VJvb"
      },
      "source": [
        "***\n",
        "## Question 4: Peer review (0pt)\n",
        "\n",
        "Finally, each group member must write a single paragraph outlining their opinion on the work distribution within the group. Did every group member contribute equally? Did you split up tasks in a fair manner, or jointly worked through the exercises. Do you think that some members of your group deserve a different grade from others?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FQaYNpLLVJvc"
      },
      "source": [
        "Timothy: We kinda failed on this assignment as a group, as all of us were a little undetermined over the week and didn't start on time and communicated enough with eachother. This is a takeaway for the next assignment.\n",
        "\n",
        "Cees: All of us underestimated the workload and the time spent on pre-processing. It took me quite some time to get the data in the correct format. I've learned a lot, but didn't make a lot of progress. I know how to approach the problem, but simply didn't have enough time to implement it. Unfortunate, but better planning next time.\n",
        "\n",
        "Celine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pO-8zuwSVJvd",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}